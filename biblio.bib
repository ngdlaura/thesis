@string{ jmlr = "Journal of Machine Learning Research (JMLR)" }
@string{ tit = "IEEE Transactions on Information Theory" }
@string{ tip = "IEEE Transactions on Image Processing (TIP)" }
@string{ tnn = "IEEE Transactions on Neural Networks" }
@string{ pami = "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)" }
@string{ ijcv = "International Journal of Computer Vision (IJCV)" }
@string{ tcs = "Theoretical Computer Science" }
@string{ neuralcomp = "Neural Computation" }
@string{ mathprog = "Mathematical Programming" }
@string{ ai = "Artificial Intelligence" }
@string{ ml = "Machine Learning" }
@string{ cvpr = "IEEE Conference on Computer Vision and Pattern Recognition (CVPR)" }
@string{ cvprw = "IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPR-W)" }
@string{ nips = "Advances in Neural Information Processing Systems (NIPS)" }
@string{ neurips = "Advances in Neural Information Processing Systems (NeurIPS)" }
@string{ neuripssub = "Under Review at Advances in Neural Information Processing Systems (NeurIPS)" }
@string{ nipsw = "Advances in Neural Information Processing Systems Workshop (NIPS-W)" }
@string{ icml = "International Conference on Machine Learning (ICML)" }
@string{ icmlw = "International Conference on Machine Learning Workshop (ICML-W)" }
@string{ ecml = "European Conference on Machine Learning (ECML)" }
@string{ eccv = "European Conference on Computer Vision (ECCV)" }
@string{ eccvw = "European Conference on Computer Vision Workshop ({ECCV-W})" }
@string{ bmvc = "{British Machine Vision Conference (BMVC)}" }
@string{ aistats = "International Conference on Artificial Intelligence and Statistics (AISTATS)" }
@string{ iclr = "International Conference on Learning Representations (ICLR)" }
@string{ ijcai = "International Joint Conferences on Artificial Intelligence (IJCAI)" }
@string{ iclrw = "International Conference on Learning Representations Workshop (ICLR-W)" }
@string{ icip = "IEEE International Conference on Image Processing (ICIP)" }
@string{ iccv = "IEEE International Conference on Computer Vision (ICCV)" }
@string{ cviu = "Computer Vision and Image Understanding (CVIU)" }
@string{ tnnls = "IEEE Transactions on Neural Networks and Learning Systems (TNNLS)" }
@string{ aaai = "Conference on Artificial Intelligence (AAAI)" }
@string{ sigir = "Special Interest Group on Information Retrieval (SIGIR)" }
@string{ arxiv = "arXiv preprint libary" }

@string{ esann = "European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN)"}

@article{wong1982document,
  title={Document analysis system},
  author={Wong, Kwan Y. and Casey, Richard G. and Wahl, Friedrich M.},
  journal={IBM journal of research and development},
  volume={26},
  number={6},
  pages={647--656},
  year={1982},
  publisher={IBM}
}

@article{britton1982effects,
  title={Effects of text structure on use of cognitive capacity during reading.},
  author={Britton, Bruce K and Glynn, Shawn M and Meyer, Bonnie J and Penland, MJ},
  journal={Journal of Educational Psychology},
  volume={74},
  number={1},
  pages={51},
  year={1982},
  publisher={American Psychological Association}
}

@incollection{burt1987laplacian,
  title={The Laplacian pyramid as a compact image code},
  author={Burt, Peter J and Adelson, Edward H},
  booktitle={Readings in computer vision},
  pages={671--679},
  year={1987},
  publisher={Elsevier}
}

@article{nagy1984hierarchical,
  title={Hierarchical representation of optically scanned documents},
  author={Nagy, George and Seth, Sharad C},
  year={1984}
}

@article{katz1987estimation,
  title={Estimation of probabilities from sparse data for the language model component of a speech recognizer},
  author={Katz, Slava},
  journal={IEEE transactions on acoustics, speech, and signal processing},
  volume={35},
  number={3},
  pages={400--401},
  year={1987},
  publisher={IEEE}
}

@article{lecun1989backpropagation,
  title={Backpropagation applied to handwritten zip code recognition},
  author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  journal={Neural computation},
  volume={1},
  number={4},
  pages={541--551},
  year={1989},
  publisher={MIT Press}
}

@article{bahl1989tree,
  title={A tree-based statistical language model for natural language speech recognition},
  author={Bahl, Lalit R and Brown, Peter F and de Souza, Peter V and Mercer, Robert L},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing},
  volume={37},
  number={7},
  pages={1001--1008},
  year={1989},
  publisher={IEEE}
}

@article{werbos1990backpropagation,
  title={Backpropagation through time: what it does and how to do it},
  author={Werbos, Paul J},
  journal={Proceedings of the IEEE},
  volume={78},
  number={10},
  pages={1550--1560},
  year={1990},
  publisher={IEEE}
}

@inproceedings{fisher1990rule,
  title={A rule-based system for document image segmentation},
  author={Fisher, James L and Hinds, Stuart C and D'Amato, Donald P},
  booktitle={[1990] Proceedings. 10th International Conference on Pattern Recognition},
  volume={1},
  pages={567--572},
  year={1990},
  organization={IEEE}
}

@inproceedings{lebourgeois1992fast,
  title={A fast and efficient method for extracting text paragraphs and graphics from unconstrained documents},
  author={Lebourgeois, Frank and Bublinski, Zbigniew and Emptoz, Hubert},
  booktitle={11th IAPR International Conference on Pattern Recognition. Vol. II. Conference B: Pattern Recognition Methodology and Systems},
  volume={1},
  pages={272--273},
  year={1992},
  organization={IEEE Computer Society}
}

@article{brown1992class,
  title={Class-based n-gram models of natural language},
  author={Brown, Peter F and Della Pietra, Vincent J and Desouza, Peter V and Lai, Jennifer C and Mercer, Robert L},
  journal={Computational linguistics},
  volume={18},
  number={4},
  pages={467--480},
  year={1992}
}

@article{marcus1993building,
  title={Building a large annotated corpus of English: The Pennf Treebank},
  author={Marcus, Mitchell and Santorini, Beatrice and Marcinkiewicz, Mary Ann},
  year={1993}
}

@article{gage1994new,
  title={A new algorithm for data compression},
  author={Gage, Philip},
  journal={C Users Journal},
  volume={12},
  number={2},
  pages={23--38},
  year={1994},
  publisher={McPherson, KS: R \& D Publications, c1987-1994.}
}

@article{jones1994natural,
  title={Natural language processing: a historical review},
  author={Jones, Karen Sparck},
  journal={Current issues in computational linguistics: in honour of Don Walker},
  pages={3--16},
  year={1994},
  publisher={Springer}
}

@article{gale1995good,
  title={Good-turing frequency estimation without tears},
  author={Gale, William A and Sampson, Geoffrey},
  journal={Journal of quantitative linguistics},
  volume={2},
  number={3},
  pages={217--237},
  year={1995},
  publisher={Taylor \& Francis}
}

@inproceedings{ha1995recursive,
  title={Recursive XY cut using bounding boxes of connected components},
  author={Ha, Jaekyu and Haralick, Robert M and Phillips, Ihsin T},
  booktitle={Proceedings of 3rd International Conference on Document Analysis and Recognition},
  volume={2},
  pages={952--955},
  year={1995},
  organization={IEEE}
}

@book{kress1996reading,
  title={Reading images: The grammar of visual design},
  author={Kress, Gunther R and Van Leeuwen, Theo and others},
  year={1996},
  publisher={Psychology Press}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}

@book{manning1999foundations,
  title={Foundations of statistical natural language processing},
  author={Manning, Christopher and Schutze, Hinrich},
  year={1999},
  publisher={MIT press}
}

@article{wright1999psychology,
  title={The psychology of layout: Consequences of the visual structure of documents},
  author={Wright, Patricia},
  journal={American Association for Artificial Intelligence Technical Report FS-99-04},
  pages={1--9},
  year={1999}
}

@incollection{ramshaw1999text,
  title={Text chunking using transformation-based learning},
  author={Ramshaw, Lance A and Marcus, Mitchell P},
  booktitle={Natural language processing using very large corpora},
  pages={157--176},
  year={1999},
  publisher={Springer}
}

@inproceedings{thede1999second,
  title={A second-order hidden Markov model for part-of-speech tagging},
  author={Thede, Scott M and Harper, Mary},
  booktitle={Proceedings of the 37th annual meeting of the Association for Computational Linguistics},
  pages={175--182},
  year={1999}
}

@article{rosenfeld2000two,
  title={Two decades of statistical language modeling: Where do we go from here?},
  author={Rosenfeld, Ronald},
  journal={Proceedings of the IEEE},
  volume={88},
  number={8},
  pages={1270--1278},
  year={2000},
  publisher={IEEE}
}

@article{bengio2000neural,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal},
  journal={Advances in neural information processing systems},
  volume={13},
  year={2000}
}

@inproceedings{petrushin2000hidden,
  title={Hidden markov models: Fundamentals and applications},
  author={Petrushin, Valery A},
  booktitle={Online Symposium for Electronics Engineer},
  year={2000}
}

@misc{hochreiter2001gradient,
  title={Gradient flow in recurrent nets: the difficulty of learning long-term dependencies},
  author={Hochreiter, Sepp and Bengio, Yoshua and Frasconi, Paolo and Schmidhuber, J{\"u}rgen and others},
  year={2001},
  publisher={A field guide to dynamical recurrent neural networks. IEEE Press In}
}

@article{hofmann2001unsupervised,
  title={Unsupervised learning by probabilistic latent semantic analysis},
  author={Hofmann, Thomas},
  journal={Machine learning},
  volume={42},
  pages={177--196},
  year={2001},
  publisher={Springer}
}

@article{amin2001page,
  title={Page segmentation and classification utilizing bottom-up approach},
  author={Amin, Adnan and Shiu, Ricky},
  journal={International Journal of Image and Graphics},
  volume={1},
  number={02},
  pages={345--361},
  year={2001},
  publisher={World Scientific}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@article{hauser2002faculty,
  title={The faculty of language: what is it, who has it, and how did it evolve?},
  author={Hauser, Marc D and Chomsky, Noam and Fitch, W Tecumseh},
  journal={science},
  volume={298},
  number={5598},
  pages={1569--1579},
  year={2002},
  publisher={American Association for the Advancement of Science}
}

@article{blei2003latent,
  title={Latent dirichlet allocation},
  author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  journal={Journal of machine Learning research},
  volume={3},
  number={Jan},
  pages={993--1022},
  year={2003}
}

@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@inproceedings{dang2005overview,
  title={Overview of DUC 2005},
  author={Dang, Hoa Trang},
  booktitle={Proceedings of the document understanding conference},
  volume={2005},
  pages={1--12},
  year={2005}
}

@article{jones2005some,
  title={Some points in a time},
  author={Jones, Karen Sp{\"a}rck},
  journal={Computational Linguistics},
  volume={31},
  number={1},
  pages={1--14},
  year={2005},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{lewis2006building,
  title={Building a test collection for complex document information processing},
  author={Lewis, David and Agam, Gady and Argamon, Shlomo and Frieder, Ophir and Grossman, D and Heard, Jefferson},
  booktitle={Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={665--666},
  year={2006}
}

@article{kendeou2007effects,
  title={The effects of prior knowledge and text structure on comprehension processes during reading of scientific texts},
  author={Kendeou, Panayiota and Van Den Broek, Paul},
  journal={Memory \& cognition},
  volume={35},
  number={7},
  pages={1567--1577},
  year={2007},
  publisher={Springer}
}

@article{kay2007tesseract,
    author = {Kay, Anthony},
    title = {Tesseract: An Open-Source Optical Character Recognition Engine},
    year = {2007},
    issue_date = {July 2007},
    publisher = {Belltown Media},
    address = {Houston, TX},
    volume = {2007},
    number = {159},
    issn = {1075-3583},
    abstract = {If you really need OCR.},
    journal = {Linux J.},
    month = Jul,
    pages = {2}
}

@article{schwenk2007continuous,
  title={Continuous space language models},
  author={Schwenk, Holger},
  journal={Computer Speech \& Language},
  volume={21},
  number={3},
  pages={492--518},
  year={2007},
  publisher={Elsevier}
}

@inproceedings{collobert2008unified,
  title={A unified architecture for natural language processing: Deep neural networks with multitask learning},
  author={Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={160--167},
  year={2008}
}

@book{turing2009computing,
  title={Computing machinery and intelligence},
  author={Turing, Alan M},
  year={2009},
  publisher={Springer}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{toprak2009three,
  title={Three reading phases and their applications in the teaching of english as a foreign language in reading classes with young learners},
  author={Toprak, Elif and Almacio{\u{g}}lu, Gamze},
  journal={Journal of language and Linguistic Studies},
  volume={5},
  number={1},
  year={2009}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@inproceedings{mikolov2010recurrent,
  title={Recurrent neural network based language model.},
  author={Mikolov, Tomas and Karafiat, Martin and Burget, Lukas and Cernocky, Jan and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  volume={2},
  number={3},
  pages={1045--1048},
  year={2010},
  organization={Makuhari}
}

@article{collobert2011natural,
  title={Natural language processing (almost) from scratch},
  author={Collobert, Ronan and Weston, Jason and Bottou, L{\'e}on and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
  journal={Journal of machine learning research},
  volume={12},
  number={ARTICLE},
  pages={2493--2537},
  year={2011}
}

@article{hilbert2011world,
  title={The world’s technological capacity to store, communicate, and compute information},
  author={Hilbert, Martin and L{\'o}pez, Priscila},
  journal={science},
  volume={332},
  number={6025},
  pages={60--65},
  year={2011},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{maas2011learning,
  title={Learning word vectors for sentiment analysis},
  author={Maas, Andrew and Daly, Raymond E and Pham, Peter T and Huang, Dan and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies},
  pages={142--150},
  year={2011}
}

@inproceedings{baechler2011multi,
  title={Multi resolution layout analysis of medieval manuscripts using dynamic mlp},
  author={Baechler, Micheal and Ingold, Rolf},
  booktitle={2011 International Conference on Document Analysis and Recognition},
  pages={1185--1189},
  year={2011},
  organization={IEEE}
}

@inproceedings{collobert2011deep,
  title={Deep learning for efficient discriminative parsing},
  author={Collobert, Ronan},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={224--232},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@inproceedings{arisoy2012deep,
  title={Deep neural network language models},
  author={Arisoy, Ebru and Sainath, Tara N and Kingsbury, Brian and Ramabhadran, Bhuvana},
  booktitle={Proceedings of the NAACL-HLT 2012 Workshop: Will We Ever Really Replace the N-gram Model? On the Future of Language Modeling for HLT},
  pages={20--28},
  year={2012}
}

@inproceedings{pradhan2012conll,
  title={CoNLL-2012 shared task: Modeling multilingual unrestricted coreference in OntoNotes},
  author={Pradhan, Sameer and Moschitti, Alessandro and Xue, Nianwen and Uryupina, Olga and Zhang, Yuchen},
  booktitle={Joint conference on EMNLP and CoNLL-shared task},
  pages={1--40},
  year={2012}
}

@article{leckner2012presentation,
  title={Presentation factors affecting reading behaviour in readers of newspaper media: an eye-tracking perspective},
  author={Leckner, Sara},
  journal={Visual Communication},
  volume={11},
  number={2},
  pages={163--184},
  year={2012},
  publisher={Sage Publications Sage UK: London, England}
}

@inproceedings{gobel2013icdar,
  title={ICDAR 2013 table competition},
  author={G{\"o}bel, Max and Hassan, Tamir and Oro, Ermelinda and Orsi, Giorgio},
  booktitle={2013 12th International Conference on Document Analysis and Recognition},
  pages={1449--1453},
  year={2013},
  organization={IEEE}
}

@inproceedings{clausner2013significance,
  title={The significance of reading order in document recognition and its evaluation},
  author={Clausner, Christian and Pletschacher, Stefan and Antonacopoulos, Apostolos},
  booktitle={2013 12th International Conference on Document Analysis and Recognition},
  pages={688--692},
  year={2013},
  organization={IEEE}
}

@article{radev2013acl,
  title={The ACL anthology network corpus},
  author={Radev, Dragomir R and Muthukrishnan, Pradeep and Qazvinian, Vahed and Abu-Jbara, Amjad},
  journal={Language Resources and Evaluation},
  volume={47},
  pages={919--944},
  year={2013},
  publisher={Springer}
}

@article{dreos2013epd,
  title={EPD and EPDnew, high-quality promoter resources in the next-generation sequencing era},
  author={Dreos, Ren{\'e} and Ambrosini, Giovanna and Cavin P{\'e}rier, Rouayda and Bucher, Philipp},
  journal={Nucleic acids research},
  volume={41},
  number={D1},
  pages={D157--D164},
  year={2013},
  publisher={Oxford University Press}
}

@inproceedings{antonacopoulos2013icdar,
  title={Icdar 2013 competition on historical newspaper layout analysis (hnla 2013)},
  author={Antonacopoulos, Apostolos and Clausner, Christian and Papadopoulos, Christos and Pletschacher, Stefan},
  booktitle={2013 12th International Conference on Document Analysis and Recognition},
  pages={1454--1458},
  year={2013},
  organization={IEEE}
}

@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1631--1642},
  year={2013}
}

@article{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1301.3781},
  year={2013}
}

@inproceedings{wei2013evaluation,
  title={Evaluation of SVM, MLP and GMM classifiers for layout analysis of historical documents},
  author={Wei, Hao and Baechler, Micheal and Slimane, Fouad and Ingold, Rolf},
  booktitle={2013 12th International Conference on Document Analysis and Recognition},
  pages={1220--1224},
  year={2013},
  organization={IEEE}
}

@article{chelba2013one,
  title={One billion word benchmark for measuring progress in statistical language modeling},
  author={Chelba, Ciprian and Mikolov, Tomas and Schuster, Mike and Ge, Qi and Brants, Thorsten and Koehn, Phillipp and Robinson, Tony},
  journal={arXiv preprint arXiv:1312.3005},
  year={2013}
}

@inproceedings{kumar2013unsupervised,
  title={Unsupervised classification of structurally similar document images},
  author={Kumar, Jayant and Doermann, David},
  booktitle={2013 12th International Conference on Document Analysis and Recognition},
  pages={1225--1229},
  year={2013},
  organization={IEEE}
}

@article{kim2014convolutional,
  title={Convolutional neural networks for sentence classification},
  author={Kim, Yoon},
  journal={arXiv preprint arXiv:1408.5882},
  year={2014}
}

@article{cho2014properties,
  title={On the properties of neural machine translation: Encoder-decoder approaches},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.1259},
  year={2014}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{kalchbrenner2014convolutional,
  title={A convolutional neural network for modelling sentences},
  author={Kalchbrenner, Nal and Grefenstette, Edward and Blunsom, Phil},
  journal={arXiv preprint arXiv:1404.2188},
  year={2014}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@article{bowman2015large,
  title={A large annotated corpus for learning natural language inference},
  author={Bowman, Samuel R and Angeli, Gabor and Potts, Christopher and Manning, Christopher D},
  journal={arXiv preprint arXiv:1508.05326},
  year={2015}
}

@inproceedings{afzal2015deepdocclassifier,
  title={Deepdocclassifier: Document classification with deep convolutional neural network},
  author={Afzal, Muhammad Zeshan and Capobianco, Samuele and Malik, Muhammad Imran and Marinai, Simone and Breuel, Thomas M and Dengel, Andreas and Liwicki, Marcus},
  booktitle={2015 13th international conference on document analysis and recognition (ICDAR)},
  pages={1111--1115},
  year={2015},
  organization={IEEE}
}

@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@inproceedings{harley2015evaluation,
  title={Evaluation of deep convolutional nets for document image classification and retrieval},
  author={Harley, Adam W and Ufkes, Alex and Derpanis, Konstantinos G},
  booktitle={2015 13th International Conference on Document Analysis and Recognition (ICDAR)},
  pages={991--995},
  year={2015},
  organization={IEEE}
}

@inproceedings{wang2015semantic,
  title={Semantic clustering and convolutional neural network for short text categorization},
  author={Wang, Peng and Xu, Jiaming and Xu, Bo and Liu, Chenglin and Zhang, Heng and Wang, Fangyuan and Hao, Hongwei},
  booktitle={Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  pages={352--357},
  year={2015}
}

@article{zhou2015predicting,
  title={Predicting effects of noncoding variants with deep learning--based sequence model},
  author={Zhou, Jian and Troyanskaya, Olga G},
  journal={Nature methods},
  volume={12},
  number={10},
  pages={931--934},
  year={2015},
  publisher={Nature Publishing Group US New York}
}

@article{zhang2015character,
  title={Character-level convolutional networks for text classification},
  author={Zhang, Xiang and Zhao, Junbo and LeCun, Yann},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{zhu2015aligning,
  title={Aligning books and movies: Towards story-like visual explanations by watching movies and reading books},
  author={Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={19--27},
  year={2015}
}

@article{pasupat2015compositional,
  title={Compositional semantic parsing on semi-structured tables},
  author={Pasupat, Panupong and Liang, Percy},
  journal={arXiv preprint arXiv:1508.00305},
  year={2015}
}

@inproceedings{nguyen2015relation,
  title={Relation extraction: Perspective from convolutional neural networks},
  author={Nguyen, Thien Huu and Grishman, Ralph},
  booktitle={Proceedings of the 1st workshop on vector space modeling for natural language processing},
  pages={39--48},
  year={2015}
}

@article{hermann2015teaching,
  title={Teaching machines to read and comprehend},
  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{pham2016convolutional,
  title={Convolutional neural network language models},
  author={Pham, Ngoc-Quan and Kruszewski, German and Boleda, Gemma},
  booktitle={Proceedings of the 2016 conference on empirical methods in natural language processing},
  pages={1153--1162},
  year={2016}
}

@article{adel2016comparing,
  title={Comparing convolutional neural networks to traditional models for slot filling},
  author={Adel, Heike and Roth, Benjamin and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:1603.05157},
  year={2016}
}

@article{shazeer2016swivel,
  title={Swivel: Improving embeddings by noticing what's missing},
  author={Shazeer, Noam and Doherty, Ryan and Evans, Colin and Waterson, Chris},
  journal={arXiv preprint arXiv:1602.02215},
  year={2016}
}

@article{rajpurkar2016squad,
  title={Squad: 100,000+ questions for machine comprehension of text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  journal={arXiv preprint arXiv:1606.05250},
  year={2016}
}

@article{wu2016google,
  title={Google's neural machine translation system: Bridging the gap between human and machine translation},
  author={Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others},
  journal={arXiv preprint arXiv:1609.08144},
  year={2016}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@book{GoodfellowDL,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    year={2016}
}

@article{merity2016pointer,
  title={Pointer sentinel mixture models},
  author={Merity, Stephen and Xiong, Caiming and Bradbury, James and Socher, Richard},
  journal={arXiv preprint arXiv:1609.07843},
  year={2016}
}

@inproceedings{hao2016table,
  title={A table detection method for pdf documents based on convolutional neural networks},
  author={Hao, Leipeng and Gao, Liangcai and Yi, Xiaohan and Tang, Zhi},
  booktitle={2016 12th IAPR Workshop on Document Analysis Systems (DAS)},
  pages={287--292},
  year={2016},
  organization={IEEE}
}

@article{jozefowicz2016exploring,
  title={Exploring the limits of language modeling},
  author={Jozefowicz, Rafal and Vinyals, Oriol and Schuster, Mike and Shazeer, Noam and Wu, Yonghui},
  journal={arXiv preprint arXiv:1602.02410},
  year={2016}
}

@article{bojanowski2017enriching,
  title={Enriching word vectors with subword information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={Transactions of the association for computational linguistics},
  volume={5},
  pages={135--146},
  year={2017},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{xie2017aggregated,
  title={Aggregated residual transformations for deep neural networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1492--1500},
  year={2017}
}

@inproceedings{gao2017icdar2017,
  title={ICDAR2017 competition on page object detection},
  author={Gao, Liangcai and Yi, Xiaohan and Jiang, Zhuoren and Hao, Leipeng and Tang, Zhi},
  booktitle={2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)},
  volume={1},
  pages={1417--1422},
  year={2017},
  organization={IEEE}
}

@inproceedings{lin2017feature,
  title={Feature pyramid networks for object detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2117--2125},
  year={2017}
}

@article{wang2017bilateral,
  title={Bilateral multi-perspective matching for natural language sentences},
  author={Wang, Zhiguo and Hamza, Wael and Florian, Radu},
  journal={arXiv preprint arXiv:1702.03814},
  year={2017}
}

@article{lai2017race,
  title={Race: Large-scale reading comprehension dataset from examinations},
  author={Lai, Guokun and Xie, Qizhe and Liu, Hanxiao and Yang, Yiming and Hovy, Eduard},
  journal={arXiv preprint arXiv:1704.04683},
  year={2017}
}

@inproceedings{yang2017learning,
  title={Learning to extract semantic structure from documents using multimodal fully convolutional neural networks},
  author={Yang, Xiao and Yumer, Ersin and Asente, Paul and Kraley, Mike and Kifer, Daniel and Lee Giles, C},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5315--5324},
  year={2017}
}

@article{joshi2017triviaqa,
  title={Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension},
  author={Joshi, Mandar and Choi, Eunsol and Weld, Daniel S and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1705.03551},
  year={2017}
}

@inproceedings{wehrmann2017character,
  title={A character-based convolutional neural network for language-agnostic Twitter sentiment analysis},
  author={Wehrmann, Joonatas and Becker, Willian and Cagnini, Henry EL and Barros, Rodrigo C},
  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)},
  pages={2384--2391},
  year={2017},
  organization={IEEE}
}

@article{olive2017processing,
  title={Processing time and cognitive effort of longhand note taking when reading and summarizing a structured or linear text},
  author={Olive, Thierry and Barbier, Marie-Laure},
  journal={Written Communication},
  volume={34},
  number={2},
  pages={224--246},
  year={2017},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{paszke2017automatic,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}

@inproceedings{das2018document,
  title={Document image classification with intra-domain transfer learning and stacked generalization of deep convolutional neural networks},
  author={Das, Arindam and Roy, Saikat and Bhattacharya, Ujjwal and Parui, Swapan K},
  booktitle={2018 24th international conference on pattern recognition (ICPR)},
  pages={3180--3185},
  year={2018},
  organization={IEEE}
}

@inproceedings{shazeer2018adafactor,
  title={Adafactor: Adaptive learning rates with sublinear memory cost},
  author={Shazeer, Noam and Stern, Mitchell},
  booktitle={International Conference on Machine Learning},
  pages={4596--4604},
  year={2018},
  organization={PMLR}
}

@inproceedings{oliveira2018dhsegment,
  title={dhSegment: A generic deep-learning approach for document segmentation},
  author={Oliveira, Sofia Ares and Seguin, Benoit and Kaplan, Frederic},
  booktitle={2018 16th International Conference on Frontiers in Handwriting Recognition (ICFHR)},
  pages={7--12},
  year={2018},
  organization={IEEE}
}

@article{shaw2018self,
  title={Self-attention with relative position representations},
  author={Shaw, Peter and Uszkoreit, Jakob and Vaswani, Ashish},
  journal={arXiv preprint arXiv:1803.02155},
  year={2018}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{peters-etal-2018-deep,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew E.  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1202",
    doi = "10.18653/v1/N18-1202",
    pages = "2227--2237",
    abstract = "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
}

@article{conneau2018senteval,
  title={Senteval: An evaluation toolkit for universal sentence representations},
  author={Conneau, Alexis and Kiela, Douwe},
  journal={arXiv preprint arXiv:1803.05449},
  year={2018}
}

@article{omar2018arabic,
  title={Arabic nested noun compound extraction based on linguistic features and statistical measures},
  author={Omar, Nazlia and Al-Tashi, Qasem},
  journal={GEMA Online{\textregistered} Journal of Language Studies},
  volume={18},
  number={2},
  year={2018}
}

@article{trinh2018simple,
  title={A simple method for commonsense reasoning},
  author={Trinh, Trieu H and Le, Quoc V},
  journal={arXiv preprint arXiv:1806.02847},
  year={2018}
}

@inproceedings{parmar2018image,
  title={Image transformer},
  author={Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Lukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},
  booktitle={International conference on machine learning},
  pages={4055--4064},
  year={2018},
  organization={PMLR}
}

@article{wang2018glue,
  title={GLUE: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1804.07461},
  year={2018}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@article{welbl2018constructing,
  title={Constructing datasets for multi-hop reading comprehension across documents},
  author={Welbl, Johannes and Stenetorp, Pontus and Riedel, Sebastian},
  journal={Transactions of the Association for Computational Linguistics},
  volume={6},
  pages={287--302},
  year={2018},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{cai2018cascade,
  title={Cascade r-cnn: Delving into high quality object detection},
  author={Cai, Zhaowei and Vasconcelos, Nuno},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6154--6162},
  year={2018}
}

@article{katti2018chargrid,
  title={Chargrid: Towards understanding 2d documents},
  author={Katti, Anoop Raveendra and Reisswig, Christian and Guder, Cordula and Brarda, Sebastian and Bickel, Steffen and H{\"o}hne, Johannes and Faddoul, Jean Baptiste},
  journal={arXiv preprint arXiv:1809.08799},
  year={2018}
}

@article{fan2018hierarchical,
  title={Hierarchical neural story generation},
  author={Fan, Angela and Lewis, Mike and Dauphin, Yann},
  journal={arXiv preprint arXiv:1805.04833},
  year={2018}
}

@inproceedings{cho2018adversarial,
  title={Adversarial tableqa: Attention supervision for question answering on tables},
  author={Cho, Minseok and Amplayo, Reinald Kim and Hwang, Seung-won and Park, Jonghyuck},
  booktitle={Asian Conference on Machine Learning},
  pages={391--406},
  year={2018},
  organization={PMLR}
}

@article{yang2018hotpotqa,
  title={HotpotQA: A dataset for diverse, explainable multi-hop question answering},
  author={Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William W and Salakhutdinov, Ruslan and Manning, Christopher D},
  journal={arXiv preprint arXiv:1809.09600},
  year={2018}
}

@article{khandelwal2018sharp,
  title={Sharp nearby, fuzzy far away: How neural language models use context},
  author={Khandelwal, Urvashi and He, He and Qi, Peng and Jurafsky, Dan},
  journal={arXiv preprint arXiv:1805.04623},
  year={2018}
}

@article{huang2018music,
  title={Music transformer},
  author={Huang, Cheng-Zhi Anna and Vaswani, Ashish and Uszkoreit, Jakob and Shazeer, Noam and Simon, Ian and Hawthorne, Curtis and Dai, Andrew M and Hoffman, Matthew D and Dinculescu, Monica and Eck, Douglas},
  journal={arXiv preprint arXiv:1809.04281},
  year={2018}
}

@article{cohan2018discourse,
  title={A discourse-aware attention model for abstractive summarization of long documents},
  author={Cohan, Arman and Dernoncourt, Franck and Kim, Doo Soon and Bui, Trung and Kim, Seokhwan and Chang, Walter and Goharian, Nazli},
  journal={arXiv preprint arXiv:1804.05685},
  year={2018}
}

@article{sharma2019bigpatent,
  title={BIGPATENT: A large-scale dataset for abstractive and coherent summarization},
  author={Sharma, Eva and Li, Chen and Wang, Lu},
  journal={arXiv preprint arXiv:1906.03741},
  year={2019}
}

@inproceedings{singh2019towards,
  title={Towards vqa models that can read},
  author={Singh, Amanpreet and Natarajan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8317--8326},
  year={2019}
}

@article{child2019generating,
  title={Generating long sequences with sparse transformers},
  author={Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1904.10509},
  year={2019}
}

@inproceedings{al2019character,
  title={Character-level language modeling with deeper self-attention},
  author={Al-Rfou, Rami and Choe, Dokook and Constant, Noah and Guo, Mandy and Jones, Llion},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={3159--3166},
  year={2019}
}

@article{reimers2019sentence,
  title={Sentence-bert: Sentence embeddings using siamese bert-networks},
  author={Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}

@article{dauphinee2019modular,
  title={Modular multimodal architecture for document classification},
  author={Dauphinee, Tyler and Patel, Nikunj and Rashidi, Mohammad},
  journal={arXiv preprint arXiv:1912.04376},
  year={2019}
}

@article{li2019tablebank,
  title={Tablebank: A benchmark dataset for table detection and recognition},
  author={Li, Minghao and Cui, Lei and Huang, Shaohan and Wei, Furu and Zhou, Ming and Li, Zhoujun},
  journal={arXiv preprint arXiv:1903.01949},
  year={2019}
}

@inproceedings{gao2019icdar,
  title={ICDAR 2019 competition on table detection and recognition (cTDaR)},
  author={Gao, Liangcai and Huang, Yilun and D{\'e}jean, Herv{\'e} and Meunier, Jean-Luc and Yan, Qinqin and Fang, Yu and Kleber, Florian and Lang, Eva},
  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},
  pages={1510--1515},
  year={2019},
  organization={IEEE}
}

@inproceedings{soto2019visual,
  title={Visual detection with context for document layout analysis},
  author={Soto, Carlos and Yoo, Shinjae},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={3464--3470},
  year={2019}
}

@article{beltagy2019scibert,
  title={Scibert: Pretrained contextualized embeddings for scientific text},
  author={Beltagy, Iz and Cohan, Arman and Lo, Kyle},
  journal={arXiv preprint arXiv:1903.10676},
  volume={1},
  number={1.3},
  pages={8},
  year={2019}
}

@article{uniprot2019uniprot,
  title={UniProt: a worldwide hub of protein knowledge},
  author={UniProt Consortium},
  journal={Nucleic acids research},
  volume={47},
  number={D1},
  pages={D506--D515},
  year={2019},
  publisher={Oxford University Press}
}

@inproceedings{duque2019squeezed,
  title={Squeezed very deep convolutional neural networks for text classification},
  author={Duque, Andr{\'e}a B and Santos, Lu{\~a} L{\'a}zaro J and Mac{\^e}do, David and Zanchettin, Cleber},
  booktitle={International Conference on Artificial Neural Networks},
  pages={193--207},
  year={2019},
  organization={Springer}
}

@article{kwiatkowski2019natural,
  title={Natural questions: a benchmark for question answering research},
  author={Kwiatkowski, Tom and Palomaki, Jennimaria and Redfield, Olivia and Collins, Michael and Parikh, Ankur and Alberti, Chris and Epstein, Danielle and Polosukhin, Illia and Devlin, Jacob and Lee, Kenton and others},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={453--466},
  year={2019},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{denk2019bertgrid,
  title={Bertgrid: Contextualized embedding for 2d document representation and understanding},
  author={Denk, Timo I and Reisswig, Christian},
  journal={arXiv preprint arXiv:1909.04948},
  year={2019}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{lewis2019bart,
  title={Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1910.13461},
  year={2019}
}

@article{lample2019cross,
  title={Cross-lingual language model pretraining},
  author={Lample, Guillaume and Conneau, Alexis},
  journal={arXiv preprint arXiv:1901.07291},
  year={2019}
}

@article{conneau2019unsupervised,
  title={Unsupervised cross-lingual representation learning at scale},
  author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1911.02116},
  year={2019}
}

@article{liu2019graph,
  title={Graph convolution for multimodal information extraction from visually rich documents},
  author={Liu, Xiaojing and Gao, Feiyu and Zhang, Qiong and Zhao, Huasha},
  journal={arXiv preprint arXiv:1903.11279},
  year={2019}
}

@inproceedings{huang2019icdar2019,
  title={Icdar2019 competition on scanned receipt ocr and information extraction},
  author={Huang, Zheng and Chen, Kai and He, Jianhua and Bai, Xiang and Karatzas, Dimosthenis and Lu, Shijian and Jawahar, CV},
  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},
  pages={1516--1520},
  year={2019},
  organization={IEEE}
}

@inproceedings{kiesel2019semeval,
  title={Semeval-2019 task 4: Hyperpartisan news detection},
  author={Kiesel, Johannes and Mestre, Maria and Shukla, Rishabh and Vincent, Emmanuel and Adineh, Payam and Corney, David and Stein, Benno and Potthast, Martin},
  booktitle={Proceedings of the 13th International Workshop on Semantic Evaluation},
  pages={829--839},
  year={2019}
}

@inproceedings{park2019cord,
  title={CORD: a consolidated receipt dataset for post-OCR parsing},
  author={Park, Seunghyun and Shin, Seung and Lee, Bado and Lee, Junyeop and Surh, Jaeheung and Seo, Minjoon and Lee, Hwalsuk},
  booktitle={Workshop on Document Intelligence at NeurIPS 2019},
  year={2019}
}

@article{xiong2019open,
  title={Open domain web keyphrase extraction beyond language modeling},
  author={Xiong, Lee and Hu, Chuan and Xiong, Chenyan and Campos, Daniel and Overwijk, Arnold},
  journal={arXiv preprint arXiv:1911.02671},
  year={2019}
}

@inproceedings{jaume2019funsd,
  title={Funsd: A dataset for form understanding in noisy scanned documents},
  author={Jaume, Guillaume and Ekenel, Hazim Kemal and Thiran, Jean-Philippe},
  booktitle={2019 International Conference on Document Analysis and Recognition Workshops (ICDARW)},
  volume={2},
  pages={1--6},
  year={2019},
  organization={IEEE}
}

@inproceedings{zhong2019publaynet,
  title={Publaynet: largest dataset ever for document layout analysis},
  author={Zhong, Xu and Tang, Jianbin and Yepes, Antonio Jimeno},
  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},
  pages={1015--1022},
  year={2019},
  organization={IEEE}
}

@article{binmakhashen2019document,
  title={Document layout analysis: a comprehensive survey},
  author={Binmakhashen, Galal M and Mahmoud, Sabri A},
  journal={ACM Computing Surveys (CSUR)},
  volume={52},
  number={6},
  pages={1--36},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{zellers2019defending,
  title={Defending against neural fake news},
  author={Zellers, Rowan and Holtzman, Ari and Rashkin, Hannah and Bisk, Yonatan and Farhadi, Ali and Roesner, Franziska and Choi, Yejin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9054--9065},
  year={2019}
}

@article{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@inproceedings{luo2019reading,
  title={Reading like HER: Human reading inspired extractive summarization},
  author={Luo, Ling and Ao, Xiang and Song, Yan and Pan, Feiyang and Yang, Min and He, Qing},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={3033--3043},
  year={2019}
}

@article{dai2019transformer,
  title={Transformer-xl: Attentive language models beyond a fixed-length context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1901.02860},
  year={2019}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{dong2019tablesense,
  title={Tablesense: Spreadsheet table detection with convolutional neural networks},
  author={Dong, Haoyu and Liu, Shijie and Han, Shi and Fu, Zhouyu and Zhang, Dongmei},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={69--76},
  year={2019}
}

@article{wolf2019huggingface,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  year={2019}
}

@article{dong2019unified,
  title={Unified language model pre-training for natural language understanding and generation},
  author={Dong, Li and Yang, Nan and Wang, Wenhui and Wei, Furu and Liu, Xiaodong and Wang, Yu and Gao, Jianfeng and Zhou, Ming and Hon, Hsiao-Wuen},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{lan2019albert,
  title={Albert: A lite bert for self-supervised learning of language representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  journal={arXiv preprint arXiv:1909.11942},
  year={2019}
}

@article{rae2019compressive,
  title={Compressive transformers for long-range sequence modelling},
  author={Rae, Jack W and Potapenko, Anna and Jayakumar, Siddhant M and Lillicrap, Timothy P},
  journal={arXiv preprint arXiv:1911.05507},
  year={2019}
}

@article{martin2019camembert,
  title={CamemBERT: a tasty French language model},
  author={Martin, Louis and Muller, Benjamin and Suárez, Pedro Javier Ortiz and Dupont, Yoann and Romary, Laurent and de La Clergerie, Éric Villemonte and Seddah, Djamé and Sagot, Benoît},
  journal={arXiv preprint arXiv:1911.03894},
  year={2019}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{jiao2019tinybert,
  title={Tinybert: Distilling bert for natural language understanding},
  author={Jiao, Xiaoqi and Yin, Yichun and Shang, Lifeng and Jiang, Xin and Chen, Xiao and Li, Linlin and Wang, Fang and Liu, Qun},
  journal={arXiv preprint arXiv:1909.10351},
  year={2019}
}

@inproceedings{xu2020layoutlm,
  title={Layoutlm: Pre-training of text and layout for document image understanding},
  author={Xu, Yiheng and Li, Minghao and Cui, Lei and Huang, Shaohan and Wei, Furu and Zhou, Ming},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1192--1200},
  year={2020}
}

@article{ding2020cogltx,
  title={Cogltx: Applying bert to long texts},
  author={Ding, Ming and Zhou, Chang and Yang, Hongxia and Tang, Jie},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12792--12804},
  year={2020}
}

@inproceedings{bao2020unilmv2,
  title={Unilmv2: Pseudo-masked language models for unified language model pre-training},
  author={Bao, Hangbo and Dong, Li and Wei, Furu and Wang, Wenhui and Yang, Nan and Liu, Xiaodong and Wang, Yu and Gao, Jianfeng and Piao, Songhao and Zhou, Ming and others},
  booktitle={International conference on machine learning},
  pages={642--652},
  year={2020},
  organization={PMLR}
}

@article{gehman2020realtoxicityprompts,
  title={Realtoxicityprompts: Evaluating neural toxic degeneration in language models},
  author={Gehman, Samuel and Gururangan, Suchin and Sap, Maarten and Choi, Yejin and Smith, Noah A},
  journal={arXiv preprint arXiv:2009.11462},
  year={2020}
}

@article{powalski2020unicase,
  title={UniCase--Rethinking Casing in Language Models},
  author={Powalski, Rafal and Stanislawek, Tomasz},
  journal={arXiv preprint arXiv:2010.11936},
  year={2020}
}

@article{zaheer2020big,
  title={Big bird: Transformers for longer sequences},
  author={Zaheer, Manzil and Guruganesh, Guru and Dubey, Kumar Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{hwang2020spatial,
  title={Spatial dependency parsing for semi-structured document information extraction},
  author={Hwang, Wonseok and Yim, Jinyeong and Park, Seunghyun and Yang, Sohee and Seo, Minjoon},
  journal={arXiv preprint arXiv:2005.00642},
  year={2020}
}

@article{kitaev2020reformer,
  title={Reformer: The Efficient Transformer},
  author={Kitaev, Nikita and Kaiser, {\L}ukasz and Levskaya, Anselm},
  journal={arXiv preprint arXiv:2001.04451},
  year={2020}
}

@inproceedings{zhong2020image,
  title={Image-based table recognition: data, model, and evaluation},
  author={Zhong, Xu and ShafieiBavani, Elaheh and Jimeno Yepes, Antonio},
  booktitle={European conference on computer vision},
  pages={564--580},
  year={2020},
  organization={Springer}
}

@article{hong2020bros,
  title={Bros: A pre-trained language model for understanding texts in document},
  author={Hong, Teakgyu and Kim, DongHyun and Ji, Mingi and Hwang, Wonseok and Nam, Daehyun and Park, Sungrae},
  year={2020}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@inproceedings{hu2020iterative,
  title={Iterative answer prediction with pointer-augmented multimodal transformers for textvqa},
  author={Hu, Ronghang and Singh, Amanpreet and Darrell, Trevor and Rohrbach, Marcus},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9992--10002},
  year={2020}
}

@article{tay2020efficient,
    author={Tay, Yi and Dehghani, Mostafa and Bahri, Dara and Metzler, Donald},
    title={Efficient Transformers: A Survey},
    journal={arXiv preprint arXiv:2009.06732},
    year={2020} 
}

@misc{arxiv2020,
    author={arXiv},
    year={2020},
    title={arXiv Bulk Data Access},
    note={\url{https://arxiv.org/help/bulk_data}} 
}

@article{scialom2020mlsum,
  title={MLSUM: The multilingual summarization corpus},
  author={Scialom, Thomas and Dray, Paul-Alexis and Lamprier, Sylvain and Piwowarski, Benjamin and Staiano, Jacopo},
  journal={arXiv preprint arXiv:2004.14900},
  year={2020}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{ke2020rethinking,
  title={Rethinking positional encoding in language pre-training},
  author={Ke, Guolin and He, Di and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:2006.15595},
  year={2020}
}

@inproceedings{prasad2020cascadetabnet,
  title={CascadeTabNet: An approach for end to end table detection and structure recognition from image-based documents},
  author={Prasad, Devashish and Gadpal, Ayan and Kapadni, Kshitij and Visave, Manish and Sultanpure, Kavita},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={572--573},
  year={2020}
}

@article{liu2020multichannel,
  title={Multichannel cnn with attention for text classification},
  author={Liu, Zhenyu and Huang, Haiwei and Lu, Chaohong and Lyu, Shengfei},
  journal={arXiv preprint arXiv:2006.16174},
  year={2020}
}

@article{lee2020biobert,
  title={BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
  author={Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  journal={Bioinformatics},
  volume={36},
  number={4},
  pages={1234--1240},
  year={2020},
  publisher={Oxford University Press}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{li2020docbank,
  title={DocBank: A benchmark dataset for document layout analysis},
  author={Li, Minghao and Xu, Yiheng and Cui, Lei and Huang, Shaohan and Wei, Furu and Li, Zhoujun and Zhou, Ming},
  journal={arXiv preprint arXiv:2006.01038},
  year={2020}
}

@article{gralinski2020kleister,
  title={Kleister: A novel task for information extraction involving long documents with complex layout},
  author={Grali{\'n}ski, Filip and Stanis{\l}awek, Tomasz and Wr{\'o}blewska, Anna and Lipi{\'n}ski, Dawid and Kaliska, Agnieszka and Rosalska, Paulina and Topolski, Bartosz and Biecek, Przemys{\l}aw},
  journal={arXiv preprint arXiv:2003.02356},
  year={2020}
}

@article{joshi2020spanbert,
  title={Spanbert: Improving pre-training by representing and predicting spans},
  author={Joshi, Mandar and Chen, Danqi and Liu, Yinhan and Weld, Daniel S and Zettlemoyer, Luke and Levy, Omer},
  journal={Transactions of the association for computational linguistics},
  volume={8},
  pages={64--77},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{liu2020multilingual,
  title={Multilingual denoising pre-training for neural machine translation},
  author={Liu, Yinhan and Gu, Jiatao and Goyal, Naman and Li, Xian and Edunov, Sergey and Ghazvininejad, Marjan and Lewis, Mike and Zettlemoyer, Luke},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={726--742},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{wang2020linformer,
  title={Linformer: Self-Attention with Linear Complexity},
  author={Wang, Sinong and Li, Belinda and Khabsa, Madian and Fang, Han and Ma, Hao},
  journal={arXiv preprint arXiv:2006.04768},
  year={2020}
}

@article{choromanski2020rethinking,
  title={Rethinking attention with performers},
  author={Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and others},
  journal={arXiv preprint arXiv:2009.14794},
  year={2020}
}

@article{pramanik2020towards,
  title={Towards a Multi-modal, Multi-task Learning based Pre-training Framework for Document Representation Learning},
  author={Pramanik, Subhojeet and Mujumdar, Shashank and Patel, Hima},
  journal={arXiv preprint arXiv:2009.14457},
  year={2020}
}


@article{tay2020long,
  title={Long Range Arena: A Benchmark for Efficient Transformers},
  author={Tay, Yi and Dehghani, Mostafa and Abnar, Samira and Shen, Yikang and Bahri, Dara and Pham, Philip and Rao, Jinfeng and Yang, Liu and Ruder, Sebastian and Metzler, Donald},
  journal={arXiv preprint arXiv:2011.04006},
  year={2020}
}


@article{ainslie2020etc,
  title={ETC: Encoding long and structured inputs in transformers},
  author={Ainslie, Joshua and Ontanon, Santiago and Alberti, Chris and Cvicek, Vaclav and Fisher, Zachary and Pham, Philip and Ravula, Anirudh and Sanghai, Sumit and Wang, Qifan and Yang, Li},
  journal={arXiv preprint arXiv:2004.08483},
  year={2020}
}

@inproceedings{zhang2020pegasus,
  title={Pegasus: Pre-training with extracted gap-sentences for abstractive summarization},
  author={Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter},
  booktitle={International Conference on Machine Learning},
  pages={11328--11339},
  year={2020},
  organization={PMLR}
}

@article{he2020deberta,
  title={Deberta: Decoding-enhanced bert with disentangled attention},
  author={He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
  journal={arXiv preprint arXiv:2006.03654},
  year={2020}
}

@article{xu2020layoutlmv2,
  title={LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding},
  author={Xu, Yang and Xu, Yiheng and Lv, Tengchao and Cui, Lei and Wei, Furu and Wang, Guoxin and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Che, Wanxiang and others},
  journal={arXiv preprint arXiv:2012.14740},
  year={2020}
}

@article{beltagy2020longformer,
  title={Longformer: The long-document transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={arXiv preprint arXiv:2004.05150},
  year={2020}
}

@article{cho2020x,
  title={X-lxmert: Paint, caption and answer questions with multi-modal transformers},
  author={Cho, Jaemin and Lu, Jiasen and Schwenk, Dustin and Hajishirzi, Hannaneh and Kembhavi, Aniruddha},
  journal={arXiv preprint arXiv:2009.11278},
  year={2020}
}

@article{sun2021long,
  title={Do long-range language models actually use long-range context?},
  author={Sun, Simeng and Krishna, Kalpesh and Mattarella-Micke, Andrew and Iyyer, Mohit},
  journal={arXiv preprint arXiv:2109.09115},
  year={2021}
}

@article{dasigi2021dataset,
  title={A dataset of information-seeking questions and answers anchored in research papers},
  author={Dasigi, Pradeep and Lo, Kyle and Beltagy, Iz and Cohan, Arman and Smith, Noah A and Gardner, Matt},
  journal={arXiv preprint arXiv:2105.03011},
  year={2021}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@misc{doctr2021,
    title={docTR: Document Text Recognition},
    author={Mindee},
    year={2021},
    publisher = {GitHub},
    howpublished = {\url{https://github.com/mindee/doctr}}
}

@article{xu2021layoutxlm,
  title={Layoutxlm: Multimodal pre-training for multilingual visually-rich document understanding},
  author={Xu, Yiheng and Lv, Tengchao and Cui, Lei and Wang, Guoxin and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Wei, Furu},
  journal={arXiv preprint arXiv:2104.08836},
  year={2021}
}

@article{sheng2021societal,
  title={Societal biases in language generation: Progress and challenges},
  author={Sheng, Emily and Chang, Kai-Wei and Natarajan, Premkumar and Peng, Nanyun},
  journal={arXiv preprint arXiv:2105.04054},
  year={2021}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}

@article{li2021structurallm,
  title={Structurallm: Structural pre-training for form understanding},
  author={Li, Chenliang and Bi, Bin and Yan, Ming and Wang, Wei and Huang, Songfang and Huang, Fei and Si, Luo},
  journal={arXiv preprint arXiv:2105.11210},
  year={2021}
}

@inproceedings{yu2021pick,
  title={PICK: processing key information extraction from documents using improved graph learning-convolutional networks},
  author={Yu, Wenwen and Lu, Ning and Qi, Xianbiao and Gong, Ping and Xiao, Rong},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)},
  pages={4363--4370},
  year={2021},
  organization={IEEE}
}

@inproceedings{kerroumi2021visualwordgrid,
  title={VisualWordGrid: Information extraction from scanned documents using a multimodal approach},
  author={Kerroumi, Mohamed and Sayem, Othmane and Shabou, Aymen},
  booktitle={International Conference on Document Analysis and Recognition},
  pages={389--402},
  year={2021},
  organization={Springer}
}

@misc{wang2021layoutreader,
      title={LayoutReader: Pre-training of Text and Layout for Reading Order Detection}, 
      author={Zilong Wang and Yiheng Xu and Lei Cui and Jingbo Shang and Furu Wei},
      year={2021},
      eprint={2108.11591},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{lin2021vibertgrid,
  title={ViBERTgrid: a jointly trained multi-modal 2D document representation for key information extraction from documents},
  author={Lin, Weihong and Gao, Qifang and Sun, Lei and Zhong, Zhuoyao and Hu, Kai and Ren, Qin and Huo, Qiang},
  booktitle={Document Analysis and Recognition--ICDAR 2021: 16th International Conference, Lausanne, Switzerland, September 5--10, 2021, Proceedings, Part I 16},
  pages={548--563},
  year={2021},
  organization={Springer}
}

@article{gehrmann2021gem,
  title={The gem benchmark: Natural language generation, its evaluation and metrics},
  author={Gehrmann, Sebastian and Adewumi, Tosin and Aggarwal, Karmanya and Ammanamanchi, Pawan Sasanka and Anuoluwapo, Aremu and Bosselut, Antoine and Chandu, Khyathi Raghavi and Clinciu, Miruna and Das, Dipanjan and Dhole, Kaustubh D and others},
  journal={arXiv preprint arXiv:2102.01672},
  year={2021}
}

@article{wu2021lampret,
  title={Lampret: Layout-aware multimodal pretraining for document understanding},
  author={Wu, Te-Lin and Li, Cheng and Zhang, Mingyang and Chen, Tao and Hombaiah, Spurthi Amba and Bendersky, Michael},
  journal={arXiv preprint arXiv:2104.08405},
  year={2021}
}

@inproceedings{li2021selfdoc,
  title={Selfdoc: Self-supervised document representation learning},
  author={Li, Peizhao and Gu, Jiuxiang and Kuen, Jason and Morariu, Vlad I and Zhao, Handong and Jain, Rajiv and Manjunatha, Varun and Liu, Hongfu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5652--5660},
  year={2021}
}

@inproceedings{mathew2021docvqa,
  title={Docvqa: A dataset for vqa on document images},
  author={Mathew, Minesh and Karatzas, Dimosthenis and Jawahar, CV},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={2200--2209},
  year={2021}
}

@article{tang2020multilingual,
  title={Multilingual translation with extensible multilingual pretraining and finetuning},
  author={Tang, Yuqing and Tran, Chau and Li, Xian and Chen, Peng-Jen and Goyal, Naman and Chaudhary, Vishrav and Gu, Jiatao and Fan, Angela},
  journal={arXiv preprint arXiv:2008.00401},
  year={2020}
}

@inproceedings{wang2021towards,
  title={Towards robust visual information extraction in real world: New dataset and novel solution},
  author={Wang, Jiapeng and Liu, Chongyu and Jin, Lianwen and Tang, Guozhi and Zhang, Jiaxin and Zhang, Shuaitao and Wang, Qianying and Wu, Yaqiang and Cai, Mingxiang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={4},
  pages={2738--2745},
  year={2021}
}

@inproceedings{tanaka2021visualmrc,
  title={Visualmrc: Machine reading comprehension on document images},
  author={Tanaka, Ryota and Nishida, Kyosuke and Yoshida, Sen},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={15},
  pages={13878--13888},
  year={2021}
}

@inproceedings{borchmann2021due,
  title={DUE: End-to-End Document Understanding Benchmark},
  author={Borchmann, {\L}ukasz and Pietruszka, Micha{\l} and Stanislawek, Tomasz and Jurkiewicz, Dawid and Turski, Micha{\l} and Szyndler, Karolina and Grali{\'n}ski, Filip},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}

@article{chaudhari2021attentive,
  title={An attentive survey of attention models},
  author={Chaudhari, Sneha and Mithal, Varun and Polatkan, Gungor and Ramanath, Rohan},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={12},
  number={5},
  pages={1--32},
  year={2021},
  publisher={ACM New York, NY}
}

@article{shen2021layoutparser,
  title={LayoutParser: A Unified Toolkit for Deep Learning Based Document Image Analysis},
  author={Shen, Zejiang and Zhang, Ruochen and Dell, Melissa and Lee, Benjamin Charles Germain and Carlson, Jacob and Li, Weining},
  journal={arXiv preprint arXiv:2103.15348},
  year={2021}
}

@article{powalski2021going,
  title={Going Full-TILT Boogie on Document Understanding with Text-Image-Layout Transformer},
  author={Powalski, Rafa{\l} and Borchmann, {\L}ukasz and Jurkiewicz, Dawid and Dwojak, Tomasz and Pietruszka, Micha{\l} and Pa{\l}ka, Gabriela},
  journal={arXiv preprint arXiv:2102.09550},
  year={2021}
}


@article{appalaraju2021docformer,
  title={DocFormer: End-to-End Transformer for Document Understanding},
  author={Appalaraju, Srikar and Jasani, Bhavan and Kota, Bhargava Urala and Xie, Yusheng and Manmatha, R},
  journal={arXiv preprint arXiv:2106.11539},
  year={2021}
}

@inproceedings{nguyen-etal-2021-skim-attention,
    title = "Skim-Attention: Learning to Focus via Document Layout",
    author = "Nguyen, Laura  and
      Scialom, Thomas  and
      Staiano, Jacopo  and
      Piwowarski, Benjamin",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.207",
    doi = "10.18653/v1/2021.findings-emnlp.207",
    pages = "2413--2427",
    abstract = "Transformer-based pre-training techniques of text and layout have proven effective in a number of document understanding tasks. Despite this success, multimodal pre-training models suffer from very high computational and memory costs. Motivated by human reading strategies, this paper presents Skim-Attention, a new attention mechanism that takes advantage of the structure of the document and its layout. Skim-Attention only attends to the 2-dimensional position of the words in a document. Our experiments show that Skim-Attention obtains a lower perplexity than prior works, while being more computationally efficient. Skim-Attention can be further combined with long-range Transformers to efficiently process long documents. We also show how Skim-Attention can be used off-the-shelf as a mask for any Pre-trained Language Model, allowing to improve their performance while restricting attention. Finally, we show the emergence of a document structure representation in Skim-Attention.",
}

@inproceedings{mathew2022infographicvqa,
  title={InfographicVQA},
  author={Mathew, Minesh and Bagal, Viraj and Tito, Rub{\`e}n and Karatzas, Dimosthenis and Valveny, Ernest and Jawahar, CV},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1697--1706},
  year={2022}
}

@article{koh2022empirical,
  title={An empirical survey on long document summarization: Datasets, models, and metrics},
  author={Koh, Huan Yee and Ju, Jiaxin and Liu, Ming and Pan, Shirui},
  journal={ACM computing surveys},
  volume={55},
  number={8},
  pages={1--35},
  year={2022},
  publisher={ACM New York, NY}
}

@article{liu2022leveraging,
  title={Leveraging locality in abstractive text summarization},
  author={Liu, Yixin and Ni, Ansong and Nan, Linyong and Deb, Budhaditya and Zhu, Chenguang and Awadallah, Ahmed H and Radev, Dragomir},
  journal={arXiv preprint arXiv:2205.12476},
  year={2022}
}

@article{clissa2022survey,
  title={Survey of Big Data sizes in 2021},
  author={Clissa, Luca},
  journal={arXiv preprint arXiv:2202.07659},
  year={2022}
}

@article{villalobos2022will,
  title={Will we run out of data? An analysis of the limits of scaling datasets in Machine Learning},
  author={Villalobos, Pablo and Sevilla, Jaime and Heim, Lennart and Besiroglu, Tamay and Hobbhahn, Marius and Ho, Anson},
  journal={arXiv preprint arXiv:2211.04325},
  year={2022}
}

@article{haviv2022transformer,
  title={Transformer language models without positional encodings still learn positional information},
  author={Haviv, Adi and Ram, Ori and Press, Ofir and Izsak, Peter and Levy, Omer},
  journal={arXiv preprint arXiv:2203.16634},
  year={2022}
}

@inproceedings{wang2022simple,
  title={A Simple yet Effective Learnable Positional Encoding Method for Improving Document Transformer Model},
  author={Wang, Guoxin and Lu, Yijuan and Cui, Lei and Lv, Tengchao and Florencio, Dinei and Zhang, Cha},
  booktitle={Findings of the Association for Computational Linguistics: AACL-IJCNLP 2022},
  pages={453--463},
  year={2022}
}

@inproceedings{gu2022xylayoutlm,
  title={Xylayoutlm: Towards layout-aware multimodal networks for visually-rich document understanding},
  author={Gu, Zhangxuan and Meng, Changhua and Wang, Ke and Lan, Jun and Wang, Weiqiang and Gu, Ming and Zhang, Liqing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4583--4592},
  year={2022}
}

@article{wang2022lilt,
  title={Lilt: A simple yet effective language-independent layout transformer for structured document understanding},
  author={Wang, Jiapeng and Jin, Lianwen and Ding, Kai},
  journal={arXiv preprint arXiv:2202.13669},
  year={2022}
}

@article{shen2022vila,
  title={VILA: Improving structured content extraction from scientific PDFs using visual layout groups},
  author={Shen, Zejiang and Lo, Kyle and Wang, Lucy Lu and Kuehl, Bailey and Weld, Daniel S and Downey, Doug},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={376--392},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@inproceedings{li2022dit,
  title={Dit: Self-supervised pre-training for document image transformer},
  author={Li, Junlong and Xu, Yiheng and Lv, Tengchao and Cui, Lei and Zhang, Cha and Wei, Furu},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={3530--3539},
  year={2022}
}

@inproceedings{kim2022ocr,
  title={Ocr-free document understanding transformer},
  author={Kim, Geewook and Hong, Teakgyu and Yim, Moonbin and Nam, JeongYeon and Park, Jinyoung and Yim, Jinyeong and Hwang, Wonseok and Yun, Sangdoo and Han, Dongyoon and Park, Seunghyun},
  booktitle={European Conference on Computer Vision},
  pages={498--517},
  year={2022},
  organization={Springer}
}

@article{pham2022understanding,
  title={Understanding long documents with different position-aware attentions},
  author={Pham, Hai and Wang, Guoxin and Lu, Yijuan and Florencio, Dinei and Zhang, Cha},
  journal={arXiv preprint arXiv:2208.08201},
  year={2022}
}

@inproceedings{huang2022layoutlmv3,
  title={Layoutlmv3: Pre-training for document ai with unified text and image masking},
  author={Huang, Yupan and Lv, Tengchao and Cui, Lei and Lu, Yutong and Wei, Furu},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={4083--4091},
  year={2022}
}

@article{qin2022nlp,
  title={The nlp task effectiveness of long-range transformers},
  author={Qin, Guanghui and Feng, Yukun and Van Durme, Benjamin},
  journal={arXiv preprint arXiv:2202.07856},
  year={2022}
}

@article{luo2022doc,
  title={Doc-gcn: Heterogeneous graph convolutional networks for document layout analysis},
  author={Luo, Siwen and Ding, Yihao and Long, Siqu and Poon, Josiah and Han, Soyeon Caren},
  journal={arXiv preprint arXiv:2208.10970},
  year={2022}
}

@article{peng2022ernie,
  title={Ernie-layout: Layout knowledge enhanced pre-training for visually-rich document understanding},
  author={Peng, Qiming and Pan, Yinxu and Wang, Wenjin and Luo, Bin and Zhang, Zhenyu and Huang, Zhengjie and Hu, Teng and Yin, Weichong and Chen, Yongfeng and Zhang, Yin and others},
  journal={arXiv preprint arXiv:2210.06155},
  year={2022}
}

@article{lee2022formnet,
  title={Formnet: Structural encoding beyond sequential modeling in form document information extraction},
  author={Lee, Chen-Yu and Li, Chun-Liang and Dozat, Timothy and Perot, Vincent and Su, Guolong and Hua, Nan and Ainslie, Joshua and Wang, Renshen and Fujii, Yasuhisa and Pfister, Tomas},
  journal={arXiv preprint arXiv:2203.08411},
  year={2022}
}

@article{miculicich2022document,
  title={Document Summarization with Text Segmentation},
  author={Miculicich, Lesly and Han, Benjamin},
  year={2022}
}

@article{scao2022bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  journal={arXiv preprint arXiv:2211.05100},
  year={2022}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{cao2022hibrids,
  title={Hibrids: Attention with hierarchical biases for structure-aware long document summarization},
  author={Cao, Shuyang and Wang, Lu},
  journal={arXiv preprint arXiv:2203.10741},
  year={2022}
}

@article{shaham2022scrolls,
  title={Scrolls: Standardized comparison over long language sequences},
  author={Shaham, Uri and Segal, Elad and Ivgi, Maor and Efrat, Avia and Yoran, Ori and Haviv, Adi and Gupta, Ankit and Xiong, Wenhan and Geva, Mor and Berant, Jonathan and others},
  journal={arXiv preprint arXiv:2201.03533},
  year={2022}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{xu-etal-2022-xfund,
    title = "{XFUND}: A Benchmark Dataset for Multilingual Visually Rich Form Understanding",
    author = "Xu, Yiheng  and
      Lv, Tengchao  and
      Cui, Lei  and
      Wang, Guoxin  and
      Lu, Yijuan  and
      Florencio, Dinei  and
      Zhang, Cha  and
      Wei, Furu",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.253",
    doi = "10.18653/v1/2022.findings-acl.253",
    pages = "3214--3224",
    abstract = "Multimodal pre-training with text, layout, and image has achieved SOTA performance for visually rich document understanding tasks recently, which demonstrates the great potential for joint learning across different modalities. However, the existed research work has focused only on the English domain while neglecting the importance of multilingual generalization. In this paper, we introduce a human-annotated multilingual form understanding benchmark dataset named XFUND, which includes form understanding samples in 7 languages (Chinese, Japanese, Spanish, French, Italian, German, Portuguese). Meanwhile, we present LayoutXLM, a multimodal pre-trained model for multilingual document understanding, which aims to bridge the language barriers for visually rich document understanding. Experimental results show that the LayoutXLM model has significantly outperformed the existing SOTA cross-lingual pre-trained models on the XFUND dataset. The XFUND dataset and the pre-trained LayoutXLM model have been publicly available at https://aka.ms/layoutxlm.",
}

@inproceedings{kovavcevic2022bidirectional,
  title={Bidirectional LSTM networks for abstractive text summarization},
  author={Kova{\v{c}}evi{\'c}, Aldin and Ke{\v{c}}o, Dino},
  booktitle={Advanced Technologies, Systems, and Applications VI: Proceedings of the International Symposium on Innovative and Interdisciplinary Applications of Advanced Technologies (IAT) 2021},
  pages={281--293},
  year={2022},
  organization={Springer}
}

@inproceedings{xu2022systematic,
  title={A systematic evaluation of large language models of code},
  author={Xu, Frank F and Alon, Uri and Neubig, Graham and Hellendoorn, Vincent Josua},
  booktitle={Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming},
  pages={1--10},
  year={2022}
}

@inproceedings{nguyen-etal-2023-loralay,
    title = "{L}o{R}a{L}ay: A Multilingual and Multimodal Dataset for Long Range and Layout-Aware Summarization",
    author = "Nguyen, Laura  and
      Scialom, Thomas  and
      Piwowarski, Benjamin  and
      Staiano, Jacopo",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.eacl-main.46",
    pages = "636--651",
    abstract = "Text Summarization is a popular task and an active area of research for the Natural Language Processing community. By definition, it requires to account for long input texts, a characteristic which poses computational challenges for neural models. Moreover, real-world documents come in a variety of complex, visually-rich, layouts. This information is of great relevance, whether to highlight salient content or to encode long-range interactions between textual passages. Yet, all publicly available summarization datasets only provide plain text content. To facilitate research on how to exploit visual/layout information to better capture long-range dependencies in summarization models, we present LoRaLay, a collection of datasets for long-range summarization with accompanying visual/layout information. We extend existing and popular English datasets (arXiv and PubMed) with layout information and propose four novel datasets {--} consistently built from scholar resources {--} covering French, Spanish, Portuguese, and Korean languages. Further, we propose new baselines merging layout-aware and long-range models {--} two orthogonal approaches {--} and obtain state-of-the-art results, showing the importance of combining both lines of research.",
}

@article{thirunavukarasu2023large,
  title={Large language models in medicine},
  author={Thirunavukarasu, Arun James and Ting, Darren Shu Jeng and Elangovan, Kabilan and Gutierrez, Laura and Tan, Ting Fang and Ting, Daniel Shu Wei},
  journal={Nature medicine},
  pages={1--11},
  year={2023},
  publisher={Nature Publishing Group US New York}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{wang2023scientific,
  title={Scientific discovery in the age of artificial intelligence},
  author={Wang, Hanchen and Fu, Tianfan and Du, Yuanqi and Gao, Wenhao and Huang, Kexin and Liu, Ziming and Chandak, Payal and Liu, Shengchao and Van Katwyk, Peter and Deac, Andreea and others},
  journal={Nature},
  volume={620},
  number={7972},
  pages={47--60},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{wang2023software,
  title={Software testing with large language model: Survey, landscape, and vision},
  author={Wang, Junjie and Huang, Yuchao and Chen, Chunyang and Liu, Zhe and Wang, Song and Wang, Qing},
  journal={arXiv preprint arXiv:2307.07221},
  year={2023}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

@article{mohamadi2023chatgpt,
  title={Chatgpt in the age of generative ai and large language models: A concise survey},
  author={Mohamadi, Salman and Mujtaba, Ghulam and Le, Ngan and Doretto, Gianfranco and Adjeroh, Donald A},
  journal={arXiv preprint arXiv:2307.04251},
  year={2023}
}

@article{hadi2023large,
  title={Large Language Models: A Comprehensive Survey of its Applications, Challenges, Limitations, and Future Prospects},
  author={Hadi, Muhammad Usman and Qureshi, Rizwan and Shah, Abbas and Irfan, Muhammad and Zafar, Anas and Shaikh, Muhammad Bilal and Akhtar, Naveed and Wu, Jia and Mirjalili, Seyedali and others},
  year={2023},
  publisher={TechRxiv}
}

@article{zhang2023reading,
  title={Reading Order Matters: Information Extraction from Visually-rich Documents by Token Path Prediction},
  author={Zhang, Chong and Guo, Ya and Tu, Yi and Chen, Huan and Tang, Jinyang and Zhu, Huijia and Zhang, Qi and Gui, Tao},
  journal={arXiv preprint arXiv:2310.11016},
  year={2023}
}

@article{bang2023multitask,
  title={A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity},
  author={Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and others},
  journal={arXiv preprint arXiv:2302.04023},
  year={2023}
}

@article{yao2023editing,
  title={Editing Large Language Models: Problems, Methods, and Opportunities},
  author={Yao, Yunzhi and Wang, Peng and Tian, Bozhong and Cheng, Siyuan and Li, Zhoubo and Deng, Shumin and Chen, Huajun and Zhang, Ningyu},
  journal={arXiv preprint arXiv:2305.13172},
  year={2023}
}

@article{ye2023comprehensive,
  title={A comprehensive capability analysis of gpt-3 and gpt-3.5 series models},
  author={Ye, Junjie and Chen, Xuanting and Xu, Nuo and Zu, Can and Shao, Zekai and Liu, Shichun and Cui, Yuhan and Zhou, Zeyang and Gong, Chao and Shen, Yang and others},
  journal={arXiv preprint arXiv:2303.10420},
  year={2023}
}

@article{jiang2023structgpt,
  title={Structgpt: A general framework for large language model to reason over structured data},
  author={Jiang, Jinhao and Zhou, Kun and Dong, Zican and Ye, Keming and Zhao, Wayne Xin and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2305.09645},
  year={2023}
}

@article{dong2023survey,
  title={A survey on long text modeling with transformers},
  author={Dong, Zican and Tang, Tianyi and Li, Lunyi and Zhao, Wayne Xin},
  journal={arXiv preprint arXiv:2302.14502},
  year={2023}
}